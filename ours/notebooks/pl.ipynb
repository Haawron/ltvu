{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/gunsbrother/prjs/ltvu/ours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /data/gunsbrother/prjs/ltvu/ours/\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    DeviceStatsMonitor,\n",
    "    LearningRateMonitor,\n",
    "    Callback,\n",
    ")\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "\n",
    "seed_everything(42, workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModule(L.LightningModule):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.model = None\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = 0\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = 0\n",
    "        val_acc = 0\n",
    "        self.log_dict({'val_loss': loss, 'val_acc': val_acc})\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = None\n",
    "        return optim\n",
    "\n",
    "model = LitModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "debug_options01 = dict(\n",
    "    fast_dev_run=10,  # vs. limit_*: runs the first 10 batches without any side effects\n",
    ")\n",
    "\n",
    "debug_options03 = dict(\n",
    "    overfit_batches=None,\n",
    ")\n",
    "\n",
    "# when an error occurred while overfitting sanity check\n",
    "# or for rapid idea iteration\n",
    "debug_options99 = dict(\n",
    "    limit_train_batches=None,  # with max_epochs=1 when doing idea validation\n",
    "    limit_val_batches=None,\n",
    "    limit_test_batches=None,\n",
    "    limit_predict_batches=None,\n",
    ")\n",
    "\n",
    "common_logger_options = dict(\n",
    "    save_dir='results/',\n",
    "    name='exp',\n",
    "    version=None,  # will automatically assign the next version number or regarded as another sub_dir if str\n",
    ")\n",
    "trainer = Trainer(\n",
    "    # important training args\n",
    "    gradient_clip_val=1.,\n",
    "    accumulate_grad_batches=4,\n",
    "    precision='bf16-mixed',\n",
    "\n",
    "    # stopping\n",
    "    max_epochs=10,\n",
    "    min_epochs=None,\n",
    "    max_time=None,\n",
    "\n",
    "    # for logging\n",
    "    logger=[\n",
    "        TensorBoardLogger(\n",
    "            sub_dir='tb/',  # TensorBoard logs will be saved in /save_dir/name/version/sub_dir\n",
    "            **common_logger_options),\n",
    "        CSVLogger(**common_logger_options),\n",
    "    ],\n",
    "    check_val_every_n_epoch=1,\n",
    "    val_check_interval=1.,  # every {int} batches or every {float in [0, 1]} epoch\n",
    "    log_every_n_steps=50,\n",
    "    enable_progress_bar=True,\n",
    "    profiler=None,  # simple, advanced\n",
    "    enable_checkpointing=False,  # False because ModelCheckpoint is used\n",
    "\n",
    "    # for on-training sanity check\n",
    "    num_sanity_val_steps=2,  # checks the first 2 batches of the val set at the start of training\n",
    "\n",
    "    # when ddp is used\n",
    "    num_nodes=1,\n",
    "    accelerator='auto',\n",
    "    devices=8,\n",
    "\n",
    "    # for reproducibility\n",
    "    deterministic=True,\n",
    "    benchmark=False,\n",
    "\n",
    "    # others\n",
    "    callbacks=[\n",
    "        # EarlyStopping(monitor='val_loss'),\n",
    "        ckpt_callback:=ModelCheckpoint(\n",
    "            # dirpath='checkpoints/',\n",
    "            monitor='val_acc', mode='max',\n",
    "        ),\n",
    "        LearningRateMonitor(\"epoch\"),\n",
    "        DeviceStatsMonitor(),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=model, train_dataloaders=None, val_dataloaders=None)\n",
    "# or\n",
    "datamodule = None\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after training\n",
    "ckpt_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model\n",
    "p_ckpt = 'asdasdasdasd'\n",
    "model_pretrained = LItEncoder.load_from_checkpoint(\n",
    "    p_ckpt,\n",
    "    #**overriding_args,\n",
    ")\n",
    "model_pretrained.freeze()  # eval mode + with no grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Note - you must have torchvision installed for this example\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class MNISTDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    def prepare_data(self):  # guarantee that only one process in DDP will download the data\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "        # or tokenize and save the data to disk\n",
    "\n",
    "        # WARNING: DO NOT assign any state (i.e. self.x = y) here\n",
    "        # because this function will be called from the main process\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\":\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(\n",
    "                mnist_full, [55000, 5000], generator=torch.Generator().manual_seed(42)\n",
    "            )\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "        if stage == \"predict\":\n",
    "            self.mnist_predict = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=32)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.mnist_predict, batch_size=32)\n",
    "\n",
    "dm = MNISTDataModule()\n",
    "model = Model()\n",
    "trainer.fit(model, datamodule=dm)\n",
    "trainer.test(datamodule=dm)\n",
    "trainer.validate(datamodule=dm)\n",
    "trainer.predict(datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPrintingCallback(Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        print(\"Training is starting\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(\"Training is ending\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltvu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
