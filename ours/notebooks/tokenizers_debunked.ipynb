{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTextEncoding\n",
    "from IPython.display import display\n",
    "print = display\n",
    "\n",
    "def tokenize(tokenizer, texts: str|list[str]):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        add_special_tokens=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=6,\n",
    "        return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tokenizer': <tokenizers.Tokenizer at 0x7f57b963a630>,\n",
       " '_decode_use_source_tokenizer': False,\n",
       " 'init_inputs': (),\n",
       " 'init_kwargs': {'do_lower_case': True,\n",
       "  'unk_token': '[UNK]',\n",
       "  'sep_token': '[SEP]',\n",
       "  'pad_token': '[PAD]',\n",
       "  'cls_token': '[CLS]',\n",
       "  'mask_token': '[MASK]',\n",
       "  'tokenize_chinese_chars': True,\n",
       "  'strip_accents': None,\n",
       "  'model_max_length': 512,\n",
       "  'name_or_path': 'distilbert-base-uncased'},\n",
       " 'name_or_path': 'distilbert-base-uncased',\n",
       " '_processor_class': None,\n",
       " 'model_max_length': 512,\n",
       " 'padding_side': 'right',\n",
       " 'truncation_side': 'right',\n",
       " 'model_input_names': ['input_ids', 'attention_mask'],\n",
       " 'clean_up_tokenization_spaces': True,\n",
       " 'split_special_tokens': False,\n",
       " 'deprecation_warnings': {},\n",
       " '_in_target_context_manager': False,\n",
       " 'chat_template': None,\n",
       " '_bos_token': None,\n",
       " '_eos_token': None,\n",
       " '_unk_token': '[UNK]',\n",
       " '_sep_token': '[SEP]',\n",
       " '_pad_token': '[PAD]',\n",
       " '_cls_token': '[CLS]',\n",
       " '_mask_token': '[MASK]',\n",
       " '_pad_token_type_id': 0,\n",
       " '_additional_special_tokens': [],\n",
       " 'verbose': False,\n",
       " 'do_lower_case': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'[PAD]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[7592, 2088,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[7592, 2088,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(tokenizer_bert.__dict__)\n",
    "print(tokenizer_bert.pad_token)\n",
    "print(tokenizer_bert.pad_token_id)\n",
    "print(tokenize(tokenizer_bert, '[PAD]'))\n",
    "print(tokenize(tokenizer_bert, 'Hello World [PAD]'))\n",
    "print(tokenize(tokenizer_bert, ['Hello World', '']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tokenizer': <tokenizers.Tokenizer at 0x7f57b9639830>,\n",
       " '_decode_use_source_tokenizer': False,\n",
       " 'init_inputs': (),\n",
       " 'init_kwargs': {'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "  'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "  'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "  'extra_ids': 100,\n",
       "  'additional_special_tokens': ['<extra_id_0>',\n",
       "   '<extra_id_1>',\n",
       "   '<extra_id_2>',\n",
       "   '<extra_id_3>',\n",
       "   '<extra_id_4>',\n",
       "   '<extra_id_5>',\n",
       "   '<extra_id_6>',\n",
       "   '<extra_id_7>',\n",
       "   '<extra_id_8>',\n",
       "   '<extra_id_9>',\n",
       "   '<extra_id_10>',\n",
       "   '<extra_id_11>',\n",
       "   '<extra_id_12>',\n",
       "   '<extra_id_13>',\n",
       "   '<extra_id_14>',\n",
       "   '<extra_id_15>',\n",
       "   '<extra_id_16>',\n",
       "   '<extra_id_17>',\n",
       "   '<extra_id_18>',\n",
       "   '<extra_id_19>',\n",
       "   '<extra_id_20>',\n",
       "   '<extra_id_21>',\n",
       "   '<extra_id_22>',\n",
       "   '<extra_id_23>',\n",
       "   '<extra_id_24>',\n",
       "   '<extra_id_25>',\n",
       "   '<extra_id_26>',\n",
       "   '<extra_id_27>',\n",
       "   '<extra_id_28>',\n",
       "   '<extra_id_29>',\n",
       "   '<extra_id_30>',\n",
       "   '<extra_id_31>',\n",
       "   '<extra_id_32>',\n",
       "   '<extra_id_33>',\n",
       "   '<extra_id_34>',\n",
       "   '<extra_id_35>',\n",
       "   '<extra_id_36>',\n",
       "   '<extra_id_37>',\n",
       "   '<extra_id_38>',\n",
       "   '<extra_id_39>',\n",
       "   '<extra_id_40>',\n",
       "   '<extra_id_41>',\n",
       "   '<extra_id_42>',\n",
       "   '<extra_id_43>',\n",
       "   '<extra_id_44>',\n",
       "   '<extra_id_45>',\n",
       "   '<extra_id_46>',\n",
       "   '<extra_id_47>',\n",
       "   '<extra_id_48>',\n",
       "   '<extra_id_49>',\n",
       "   '<extra_id_50>',\n",
       "   '<extra_id_51>',\n",
       "   '<extra_id_52>',\n",
       "   '<extra_id_53>',\n",
       "   '<extra_id_54>',\n",
       "   '<extra_id_55>',\n",
       "   '<extra_id_56>',\n",
       "   '<extra_id_57>',\n",
       "   '<extra_id_58>',\n",
       "   '<extra_id_59>',\n",
       "   '<extra_id_60>',\n",
       "   '<extra_id_61>',\n",
       "   '<extra_id_62>',\n",
       "   '<extra_id_63>',\n",
       "   '<extra_id_64>',\n",
       "   '<extra_id_65>',\n",
       "   '<extra_id_66>',\n",
       "   '<extra_id_67>',\n",
       "   '<extra_id_68>',\n",
       "   '<extra_id_69>',\n",
       "   '<extra_id_70>',\n",
       "   '<extra_id_71>',\n",
       "   '<extra_id_72>',\n",
       "   '<extra_id_73>',\n",
       "   '<extra_id_74>',\n",
       "   '<extra_id_75>',\n",
       "   '<extra_id_76>',\n",
       "   '<extra_id_77>',\n",
       "   '<extra_id_78>',\n",
       "   '<extra_id_79>',\n",
       "   '<extra_id_80>',\n",
       "   '<extra_id_81>',\n",
       "   '<extra_id_82>',\n",
       "   '<extra_id_83>',\n",
       "   '<extra_id_84>',\n",
       "   '<extra_id_85>',\n",
       "   '<extra_id_86>',\n",
       "   '<extra_id_87>',\n",
       "   '<extra_id_88>',\n",
       "   '<extra_id_89>',\n",
       "   '<extra_id_90>',\n",
       "   '<extra_id_91>',\n",
       "   '<extra_id_92>',\n",
       "   '<extra_id_93>',\n",
       "   '<extra_id_94>',\n",
       "   '<extra_id_95>',\n",
       "   '<extra_id_96>',\n",
       "   '<extra_id_97>',\n",
       "   '<extra_id_98>',\n",
       "   '<extra_id_99>'],\n",
       "  'model_max_length': 512,\n",
       "  'name_or_path': 'google/flan-t5-base',\n",
       "  'sp_model_kwargs': {},\n",
       "  'special_tokens_map_file': '/home/younes_huggingface_co/.cache/huggingface/hub/models--google--t5-v1_1-base/snapshots/650d7745bf1e502d6949b22cc19155cd656d3d4e/special_tokens_map.json'},\n",
       " 'name_or_path': 'google/flan-t5-base',\n",
       " '_processor_class': None,\n",
       " 'model_max_length': 512,\n",
       " 'padding_side': 'right',\n",
       " 'truncation_side': 'right',\n",
       " 'model_input_names': ['input_ids', 'attention_mask'],\n",
       " 'clean_up_tokenization_spaces': True,\n",
       " 'split_special_tokens': False,\n",
       " 'deprecation_warnings': {},\n",
       " '_in_target_context_manager': False,\n",
       " 'chat_template': None,\n",
       " '_bos_token': None,\n",
       " '_eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " '_unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " '_sep_token': None,\n",
       " '_pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " '_cls_token': None,\n",
       " '_mask_token': None,\n",
       " '_pad_token_type_id': 0,\n",
       " '_additional_special_tokens': ['<extra_id_0>',\n",
       "  '<extra_id_1>',\n",
       "  '<extra_id_2>',\n",
       "  '<extra_id_3>',\n",
       "  '<extra_id_4>',\n",
       "  '<extra_id_5>',\n",
       "  '<extra_id_6>',\n",
       "  '<extra_id_7>',\n",
       "  '<extra_id_8>',\n",
       "  '<extra_id_9>',\n",
       "  '<extra_id_10>',\n",
       "  '<extra_id_11>',\n",
       "  '<extra_id_12>',\n",
       "  '<extra_id_13>',\n",
       "  '<extra_id_14>',\n",
       "  '<extra_id_15>',\n",
       "  '<extra_id_16>',\n",
       "  '<extra_id_17>',\n",
       "  '<extra_id_18>',\n",
       "  '<extra_id_19>',\n",
       "  '<extra_id_20>',\n",
       "  '<extra_id_21>',\n",
       "  '<extra_id_22>',\n",
       "  '<extra_id_23>',\n",
       "  '<extra_id_24>',\n",
       "  '<extra_id_25>',\n",
       "  '<extra_id_26>',\n",
       "  '<extra_id_27>',\n",
       "  '<extra_id_28>',\n",
       "  '<extra_id_29>',\n",
       "  '<extra_id_30>',\n",
       "  '<extra_id_31>',\n",
       "  '<extra_id_32>',\n",
       "  '<extra_id_33>',\n",
       "  '<extra_id_34>',\n",
       "  '<extra_id_35>',\n",
       "  '<extra_id_36>',\n",
       "  '<extra_id_37>',\n",
       "  '<extra_id_38>',\n",
       "  '<extra_id_39>',\n",
       "  '<extra_id_40>',\n",
       "  '<extra_id_41>',\n",
       "  '<extra_id_42>',\n",
       "  '<extra_id_43>',\n",
       "  '<extra_id_44>',\n",
       "  '<extra_id_45>',\n",
       "  '<extra_id_46>',\n",
       "  '<extra_id_47>',\n",
       "  '<extra_id_48>',\n",
       "  '<extra_id_49>',\n",
       "  '<extra_id_50>',\n",
       "  '<extra_id_51>',\n",
       "  '<extra_id_52>',\n",
       "  '<extra_id_53>',\n",
       "  '<extra_id_54>',\n",
       "  '<extra_id_55>',\n",
       "  '<extra_id_56>',\n",
       "  '<extra_id_57>',\n",
       "  '<extra_id_58>',\n",
       "  '<extra_id_59>',\n",
       "  '<extra_id_60>',\n",
       "  '<extra_id_61>',\n",
       "  '<extra_id_62>',\n",
       "  '<extra_id_63>',\n",
       "  '<extra_id_64>',\n",
       "  '<extra_id_65>',\n",
       "  '<extra_id_66>',\n",
       "  '<extra_id_67>',\n",
       "  '<extra_id_68>',\n",
       "  '<extra_id_69>',\n",
       "  '<extra_id_70>',\n",
       "  '<extra_id_71>',\n",
       "  '<extra_id_72>',\n",
       "  '<extra_id_73>',\n",
       "  '<extra_id_74>',\n",
       "  '<extra_id_75>',\n",
       "  '<extra_id_76>',\n",
       "  '<extra_id_77>',\n",
       "  '<extra_id_78>',\n",
       "  '<extra_id_79>',\n",
       "  '<extra_id_80>',\n",
       "  '<extra_id_81>',\n",
       "  '<extra_id_82>',\n",
       "  '<extra_id_83>',\n",
       "  '<extra_id_84>',\n",
       "  '<extra_id_85>',\n",
       "  '<extra_id_86>',\n",
       "  '<extra_id_87>',\n",
       "  '<extra_id_88>',\n",
       "  '<extra_id_89>',\n",
       "  '<extra_id_90>',\n",
       "  '<extra_id_91>',\n",
       "  '<extra_id_92>',\n",
       "  '<extra_id_93>',\n",
       "  '<extra_id_94>',\n",
       "  '<extra_id_95>',\n",
       "  '<extra_id_96>',\n",
       "  '<extra_id_97>',\n",
       "  '<extra_id_98>',\n",
       "  '<extra_id_99>'],\n",
       " 'verbose': False,\n",
       " 'vocab_file': '/data/gunsbrother/prjs/ltvu/ours/cache_dir/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/spiece.model',\n",
       " '_extra_ids': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 784, 3965,  308,  908,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[8774, 1150,  784, 3965,  308,  908]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[8774, 1150,    0,    0,    0,    0],\n",
       "        [ 784, 3965,  308,  908,    0,    0]]), 'attention_mask': tensor([[1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_t5 = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "print(tokenizer_t5.__dict__)\n",
    "print(tokenizer_t5.pad_token)\n",
    "print(tokenizer_t5.pad_token_id)\n",
    "print(tokenize(tokenizer_t5, '[PAD]'))\n",
    "print(tokenize(tokenizer_t5, 'Hello World [PAD]'))\n",
    "print(tokenize(tokenizer_t5, ['Hello World', '[PAD]']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 8774,  1150,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0],\n",
       "        [   38,    26,    29,     9,     7,   157],\n",
       "        [   71,     0,     0,     0,     0,     0],\n",
       "        [32099,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(tokenizer_t5, ['Hello World', '<pad>', 'asdnaskjdnasd', 'A', '<extra_id_0>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tokenizer_bert.unk_token_id)\n",
    "print(tokenizer_t5.unk_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21820,    55,     0,     0,     0,     0],\n",
       "        [21820,     0,     0,     0,     0,     0],\n",
       "        [ 7102,     0,     0,     0,     0,     0],\n",
       "        [ 2952,     0,     0,     0,     0,     0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 768])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.0845, 8.7947, 8.7947, 8.7947, 8.7947, 8.7947],\n",
       "        [9.3018, 9.3946, 9.3946, 9.3946, 9.3946, 9.3946],\n",
       "        [8.7500, 9.0515, 9.0515, 9.0515, 9.0515, 9.0515],\n",
       "        [9.5683, 9.8422, 9.8422, 9.8422, 9.8422, 9.8422],\n",
       "        [9.4612, 9.7255, 9.7255, 9.7255, 9.7255, 9.7255],\n",
       "        [9.3690, 9.6484, 9.6484, 9.6484, 9.6484, 9.6484]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5.7617, 5.6379, 5.6379, 5.6379, 5.6379, 5.6379],\n",
       "        [5.9998, 6.0905, 6.0905, 6.0905, 6.0905, 6.0905],\n",
       "        [4.4810, 4.8266, 4.8266, 4.8266, 4.8266, 4.8266],\n",
       "        [5.3295, 5.6353, 5.6353, 5.6353, 5.6353, 5.6353],\n",
       "        [5.3032, 5.6060, 5.6060, 5.6060, 5.6060, 5.6060],\n",
       "        [5.1105, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[8.3215, 8.7553, 8.7553, 8.7553, 8.7553, 8.7553],\n",
       "        [8.3254, 8.2437, 8.2437, 8.2437, 8.2437, 8.2437],\n",
       "        [8.9605, 9.0942, 9.0942, 9.0942, 9.0942, 9.0942],\n",
       "        [9.5316, 9.6606, 9.6606, 9.6606, 9.6606, 9.6606],\n",
       "        [9.3429, 9.4575, 9.4575, 9.4575, 9.4575, 9.4575],\n",
       "        [9.4272, 9.5588, 9.5588, 9.5588, 9.5588, 9.5588]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "flant5_encoder = AutoModelForTextEncoding.from_pretrained('google/flan-t5-base').eval()\n",
    "tokens = tokenize(tokenizer_t5, ['hello!', 'hello', 'hi', 'panel'])\n",
    "z = flant5_encoder.forward(**tokens).last_hidden_state\n",
    "print(tokens.input_ids)\n",
    "print(z.shape)\n",
    "print(z[0] @ z[1].T)\n",
    "print(z[0] @ z[2].T)\n",
    "print(z[0] @ z[3].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name google/flan-t5-base. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 768])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.0845, 8.7947, 8.7947, 8.7947, 8.7947, 8.7947],\n",
       "        [9.3018, 9.3946, 9.3946, 9.3946, 9.3946, 9.3946],\n",
       "        [8.7500, 9.0515, 9.0515, 9.0515, 9.0515, 9.0515],\n",
       "        [9.5683, 9.8422, 9.8422, 9.8422, 9.8422, 9.8422],\n",
       "        [9.4612, 9.7255, 9.7255, 9.7255, 9.7255, 9.7255],\n",
       "        [9.3690, 9.6484, 9.6484, 9.6484, 9.6484, 9.6484]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5.7617, 5.6379, 5.6379, 5.6379, 5.6379, 5.6379],\n",
       "        [5.9998, 6.0905, 6.0905, 6.0905, 6.0905, 6.0905],\n",
       "        [4.4810, 4.8266, 4.8266, 4.8266, 4.8266, 4.8266],\n",
       "        [5.3295, 5.6353, 5.6353, 5.6353, 5.6353, 5.6353],\n",
       "        [5.3032, 5.6060, 5.6060, 5.6060, 5.6060, 5.6060],\n",
       "        [5.1105, 5.4193, 5.4193, 5.4193, 5.4193, 5.4193]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[8.3215, 8.7553, 8.7553, 8.7553, 8.7553, 8.7553],\n",
       "        [8.3254, 8.2437, 8.2437, 8.2437, 8.2437, 8.2437],\n",
       "        [8.9605, 9.0942, 9.0942, 9.0942, 9.0942, 9.0942],\n",
       "        [9.5316, 9.6606, 9.6606, 9.6606, 9.6606, 9.6606],\n",
       "        [9.3429, 9.4575, 9.4575, 9.4575, 9.4575, 9.4575],\n",
       "        [9.4272, 9.5588, 9.5588, 9.5588, 9.5588, 9.5588]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('google/flan-t5-base').eval()\n",
    "z = model.forward(tokens).token_embeddings\n",
    "\n",
    "print(z.shape)\n",
    "print(z[0] @ z[1].T)\n",
    "print(z[0] @ z[2].T)\n",
    "print(z[0] @ z[3].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2834,  0.1011,  0.0958,  ..., -0.1644,  0.2118, -0.0417],\n",
       "        [-0.1202,  0.1066, -0.3856,  ...,  0.0695,  0.1300,  0.0754],\n",
       "        [ 0.0241,  0.1043, -0.4156,  ..., -0.0125,  0.0847,  0.0967],\n",
       "        [-0.1193,  0.2418, -0.2466,  ..., -0.0072, -0.0075,  0.0690]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(tokens).sentence_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내 모델 vs. GVQA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name google/flan-t5-base. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['shared.weight',\n",
       " 'encoder.embed_tokens.weight',\n",
       " 'encoder.block.0.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.0.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.0.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.0.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
       " 'encoder.block.0.layer.0.layer_norm.weight',\n",
       " 'encoder.block.0.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.0.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.0.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.0.layer.1.layer_norm.weight',\n",
       " 'encoder.block.1.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.1.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.1.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.1.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.1.layer.0.layer_norm.weight',\n",
       " 'encoder.block.1.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.1.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.1.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.1.layer.1.layer_norm.weight',\n",
       " 'encoder.block.2.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.2.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.2.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.2.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.2.layer.0.layer_norm.weight',\n",
       " 'encoder.block.2.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.2.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.2.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.2.layer.1.layer_norm.weight',\n",
       " 'encoder.block.3.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.3.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.3.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.3.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.3.layer.0.layer_norm.weight',\n",
       " 'encoder.block.3.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.3.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.3.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.3.layer.1.layer_norm.weight',\n",
       " 'encoder.block.4.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.4.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.4.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.4.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.4.layer.0.layer_norm.weight',\n",
       " 'encoder.block.4.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.4.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.4.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.4.layer.1.layer_norm.weight',\n",
       " 'encoder.block.5.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.5.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.5.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.5.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.5.layer.0.layer_norm.weight',\n",
       " 'encoder.block.5.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.5.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.5.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.5.layer.1.layer_norm.weight',\n",
       " 'encoder.block.6.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.6.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.6.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.6.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.6.layer.0.layer_norm.weight',\n",
       " 'encoder.block.6.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.6.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.6.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.6.layer.1.layer_norm.weight',\n",
       " 'encoder.block.7.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.7.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.7.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.7.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.7.layer.0.layer_norm.weight',\n",
       " 'encoder.block.7.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.7.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.7.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.7.layer.1.layer_norm.weight',\n",
       " 'encoder.block.8.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.8.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.8.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.8.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.8.layer.0.layer_norm.weight',\n",
       " 'encoder.block.8.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.8.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.8.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.8.layer.1.layer_norm.weight',\n",
       " 'encoder.block.9.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.9.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.9.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.9.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.9.layer.0.layer_norm.weight',\n",
       " 'encoder.block.9.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.9.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.9.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.9.layer.1.layer_norm.weight',\n",
       " 'encoder.block.10.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.10.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.10.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.10.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.10.layer.0.layer_norm.weight',\n",
       " 'encoder.block.10.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.10.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.10.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.10.layer.1.layer_norm.weight',\n",
       " 'encoder.block.11.layer.0.SelfAttention.q.weight',\n",
       " 'encoder.block.11.layer.0.SelfAttention.k.weight',\n",
       " 'encoder.block.11.layer.0.SelfAttention.v.weight',\n",
       " 'encoder.block.11.layer.0.SelfAttention.o.weight',\n",
       " 'encoder.block.11.layer.0.layer_norm.weight',\n",
       " 'encoder.block.11.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'encoder.block.11.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'encoder.block.11.layer.1.DenseReluDense.wo.weight',\n",
       " 'encoder.block.11.layer.1.layer_norm.weight',\n",
       " 'encoder.final_layer_norm.weight']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from ltvu.models.without_rgb.lightning_modules import TextOnlyNLQLitModule\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "lit = TextOnlyNLQLitModule(model_name='google/flan-t5-base', head_name='af')\n",
    "# base_model = SentenceTransformer('google/flan-t5-base')\n",
    "list(lit.model.lm[0].auto_model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.v_emb',\n",
       " 'model.lm.shared.weight',\n",
       " 'model.lm.encoder.embed_tokens.weight',\n",
       " 'model.lm.encoder.block.0.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.0.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.0.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.0.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
       " 'model.lm.encoder.block.0.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.0.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.0.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.0.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.0.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.1.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.1.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.1.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.1.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.1.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.1.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.1.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.1.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.1.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.2.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.2.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.2.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.2.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.2.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.2.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.2.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.2.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.2.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.3.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.3.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.3.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.3.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.3.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.3.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.3.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.3.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.3.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.4.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.4.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.4.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.4.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.4.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.4.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.4.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.4.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.4.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.5.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.5.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.5.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.5.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.5.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.5.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.5.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.5.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.5.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.6.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.6.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.6.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.6.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.6.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.6.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.6.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.6.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.6.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.7.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.7.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.7.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.7.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.7.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.7.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.7.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.7.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.7.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.8.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.8.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.8.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.8.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.8.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.8.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.8.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.8.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.8.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.9.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.9.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.9.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.9.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.9.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.9.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.9.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.9.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.9.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.10.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.10.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.10.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.10.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.10.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.10.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.10.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.10.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.10.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.block.11.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.encoder.block.11.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.encoder.block.11.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.encoder.block.11.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.encoder.block.11.layer.0.layer_norm.weight',\n",
       " 'model.lm.encoder.block.11.layer.1.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.encoder.block.11.layer.1.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.encoder.block.11.layer.1.DenseReluDense.wo.weight',\n",
       " 'model.lm.encoder.block.11.layer.1.layer_norm.weight',\n",
       " 'model.lm.encoder.final_layer_norm.weight',\n",
       " 'model.lm.decoder.embed_tokens.weight',\n",
       " 'model.lm.decoder.block.0.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.0.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.0.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.0.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
       " 'model.lm.decoder.block.0.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.0.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.0.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.0.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.0.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.0.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.0.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.0.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.0.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.0.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.1.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.1.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.1.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.1.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.1.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.1.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.1.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.1.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.1.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.1.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.1.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.1.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.1.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.1.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.2.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.2.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.2.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.2.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.2.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.2.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.2.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.2.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.2.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.2.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.2.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.2.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.2.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.2.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.3.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.3.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.3.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.3.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.3.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.3.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.3.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.3.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.3.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.3.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.3.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.3.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.3.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.3.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.4.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.4.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.4.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.4.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.4.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.4.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.4.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.4.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.4.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.4.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.4.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.4.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.4.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.4.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.5.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.5.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.5.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.5.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.5.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.5.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.5.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.5.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.5.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.5.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.5.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.5.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.5.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.5.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.6.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.6.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.6.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.6.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.6.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.6.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.6.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.6.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.6.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.6.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.6.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.6.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.6.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.6.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.7.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.7.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.7.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.7.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.7.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.7.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.7.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.7.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.7.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.7.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.7.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.7.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.7.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.7.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.8.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.8.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.8.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.8.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.8.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.8.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.8.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.8.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.8.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.8.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.8.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.8.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.8.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.8.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.9.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.9.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.9.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.9.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.9.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.9.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.9.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.9.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.9.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.9.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.9.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.9.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.9.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.9.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.10.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.10.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.10.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.10.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.10.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.10.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.10.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.10.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.10.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.10.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.10.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.10.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.10.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.10.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.block.11.layer.0.SelfAttention.q.weight',\n",
       " 'model.lm.decoder.block.11.layer.0.SelfAttention.k.weight',\n",
       " 'model.lm.decoder.block.11.layer.0.SelfAttention.v.weight',\n",
       " 'model.lm.decoder.block.11.layer.0.SelfAttention.o.weight',\n",
       " 'model.lm.decoder.block.11.layer.0.layer_norm.weight',\n",
       " 'model.lm.decoder.block.11.layer.1.EncDecAttention.q.weight',\n",
       " 'model.lm.decoder.block.11.layer.1.EncDecAttention.k.weight',\n",
       " 'model.lm.decoder.block.11.layer.1.EncDecAttention.v.weight',\n",
       " 'model.lm.decoder.block.11.layer.1.EncDecAttention.o.weight',\n",
       " 'model.lm.decoder.block.11.layer.1.layer_norm.weight',\n",
       " 'model.lm.decoder.block.11.layer.2.DenseReluDense.wi_0.weight',\n",
       " 'model.lm.decoder.block.11.layer.2.DenseReluDense.wi_1.weight',\n",
       " 'model.lm.decoder.block.11.layer.2.DenseReluDense.wo.weight',\n",
       " 'model.lm.decoder.block.11.layer.2.layer_norm.weight',\n",
       " 'model.lm.decoder.final_layer_norm.weight',\n",
       " 'model.lm.lm_head.weight',\n",
       " 'model.lm_proj.weight',\n",
       " 'model.lm_proj.bias',\n",
       " 'model.nlq_head.neck.fpn_norms.0.weight',\n",
       " 'model.nlq_head.neck.fpn_norms.0.bias',\n",
       " 'model.nlq_head.cls_head.head.0.conv.weight',\n",
       " 'model.nlq_head.cls_head.head.1.conv.weight',\n",
       " 'model.nlq_head.cls_head.norm.0.weight',\n",
       " 'model.nlq_head.cls_head.norm.0.bias',\n",
       " 'model.nlq_head.cls_head.norm.1.weight',\n",
       " 'model.nlq_head.cls_head.norm.1.bias',\n",
       " 'model.nlq_head.cls_head.cls_head.conv.weight',\n",
       " 'model.nlq_head.cls_head.cls_head.conv.bias',\n",
       " 'model.nlq_head.reg_head.head.0.conv.weight',\n",
       " 'model.nlq_head.reg_head.head.1.conv.weight',\n",
       " 'model.nlq_head.reg_head.norm.0.weight',\n",
       " 'model.nlq_head.reg_head.norm.0.bias',\n",
       " 'model.nlq_head.reg_head.norm.1.weight',\n",
       " 'model.nlq_head.reg_head.norm.1.bias',\n",
       " 'model.nlq_head.reg_head.scale.0.scale',\n",
       " 'model.nlq_head.reg_head.offset_head.conv.weight',\n",
       " 'model.nlq_head.reg_head.offset_head.conv.bias']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ckpt = '/data/gunsbrother/prjs/ltvu/llms/GroundVQA/GroundVQA/GroundVQA_B-NLQ_NaQ-finetune_NLQ-VLG-val_R1_03=29.7.ckpt'\n",
    "state_dict = torch.load(p_ckpt, map_location='cpu')\n",
    "list(state_dict['state_dict'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['state_dict']['model.v_emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 768, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['state_dict']['model.nlq_head.reg_head.head.0.conv.weight'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltvu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
